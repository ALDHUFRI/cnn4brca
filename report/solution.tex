\chapter{Solution}
\label{ch:Model}

% We [outline|describe|introduce] our [proposed] [solution|model], [justify] design decisions and [implementation details| detail implementation| document implementation details].
In this chapter, we describe our experiments, justify design decisions and detail our implementation. A high-level overview of our solution is provided in Fig.~\ref{fig:overview}. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{plots/overview.pdf}
	\caption[Overview of the solution]{Overview of our solution. We divide the database into training and test patients, preprocess the mammograms, train a convolutional network with the training set (we select hyperparameters $\alpha$ and $\lambda$ using part of the training set for validation) and evaluate our model in the test set. Each experiment tests different network and training configurations.}
	%Experiment 1 and 3 repeat this for 5 folds while Experiment 2 uses a single fold
	\label{fig:overview}
\end{figure}

\section{Task definition}
We segment digital mammograms into two separate regions: breast mass (benign or malignant) and general tissue.
Breast area is previously separated from the background by simple thresholding.
In particular, we train a convolutional network to estimate the probability of each pixel belonging to a mass and use these predictions to generate a valid segmentation.

\section{Data set}
\input{solution/dataset}

\section{Experiment 1}
\label{sec:Experiment1}
\input{solution/experiment1}

\section{Experiment 2}
\label{sec:Experiment2}
\input{solution/experiment2}

\section{Experiment 3}
\label{sec:Experiment3}
\input{solution/experiment3}

\section{Training}
\input{solution/training}

\section{Evaluation}
\input{solution/evaluation}

\section{Summary}
Mammograms from the BCDR-D01 database were enhanced, resized and divided to obtain our data set. An architecture based on the VGG network (9 layers, 2.9M parameters) was used for the first experiments, one of which used a weighted loss function to fight class imbalance. A different architecture based on the Residual network (10 layers, 0.9M parameters) was used for the last experiment. We performed hyperparameter search to fine tune the learning rate and regularization parameter of each network; other hyperparameters were set manually. Networks were written in TensorFlow and optimized using ADAM. Using a validation set, we selected a threshold to produce the final segmentation from the heatmap of predictions. Many different performance metrics are reported.

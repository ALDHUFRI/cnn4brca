\chapter{Results}
\label{ch:results}
We show the results of the different experiments and discuss their implications.

\section{Experiment 1}
\subsection{Hyperparameter search}
After running the first batch of hyperparameter search, the best $\lambda$ and $\alpha$ values appear closer to the bottom of the search range with the best lambda ranging from 0-0.15 and the best alpha in 0.000001 to 0.0001 (Fig.~\ref{fig:hs1}).

figures

% Discussion: Divergenece and it can be also observed that lambda is not as important as alpha.
After refining the search range we obtained a better idea of which values could work. 

figures

Finally, we chose to train a network with $\alpha = 0.000004$ and $\lambda = 0.0008$.

\subsection{Evaluation}
We show the validation logistic loss and training loss.

threshold with 0.133 in validation set (still don't know in test set).

\subsection{Qualitatiuve results}
images of actual segmentations in the test set

\section{Experiment 2}
\subsection{Hyperparameter search}
\subsection{Evaluation}
\subsection{Qualitative results}


\section{Discussion}
We found that....

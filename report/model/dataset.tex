%We document the retrieval, enhancement, labelling and augmentation of [the|our] data set [used for the experiments].
% We document how we retrieve, enhance, label and augment our data set.
We document the retrieval, enhancement, labelling and augmentation of our data set.

	\subsection{Database}
We have decided to use digital over film mammograms. Digital mammograms are sharper and do not have marks, stamps or other artifacts present in digitised film mammograms. On the downside, because the technology is newer it may be harder to obtain big databases and given its higher resolution they are normally heavier in terms of disk space. We believe the network will be able to pick up better features from the higher quality images and that the size on disk will not be a trouble given the storage availability on current computers. A small number of examples in the database is a big problem and some alternatives are offered below in case the network is not able to learn with the available data. For these reasons, we have decided to use initially the BCDR-DM and INbreast databases.
%BCDR
%A small desciption is offered below.

%	\subsubsection{BCDR-DM}
%	Yet to write
% Files and how are they organized. Data available per case and per mammogram. How are boundaries written. formats, etc.
% 159 calcifications, 36 micro, 11 micro+calcif, thus 108 micro or calcif. 106 nodule, 20 nodule+ calcific, 11 nodule + micro
	
	\subsection{Image retrieval/Preprocessing}
	\input{model/imageRetrieval} 
% Images will not be zero-centered , normalized or whitened. global contrast
% with global contrast stretching will make comparisons across patients not good, because if a pixel is very bright in one patient that is only important with respect to that patient and it may end up (by contrast stretching) having the same value that the pixel in another mammogram who wasn't as bright but was the brightest of the mammogram. i think this makes sense because masss are going ot be bright but only in relation to the patient, maybe one has very fatty tissue so all is white and others have very clear tissue.
% Labels are background, lession and breast tissue. 
% Or could I crop the figure closely to the background and then calculate over all spaces (nop). How do you backpropagate through this mask? Just assign perfect scores to evry position in your predictions that is background (check where is the background in the mask), that way it will be counted by normal gradient, but it will not contribute. I could add a layer at the end (or before the loss function), that sets the gradient to zero in the backwards pass if the position it is viewing is  a background pixel. that'll do it.
% Or i could assume that anythong under the global mean won't be a mass and then during classification and during training just set them to black/treat them as background (this owuld be the equivalent ot train them and test them only on those pixels that are greater than the global means0). But maybe this then reduces the data se too much and I won't learn. More or less half the values are gonna go to zero. I would need to create a label where evrything below the global mena is background (0), any lession is (1) and any other breats tissue  is (0.5). Overcomplicated, better let the network also see some black patches maybe that help it. do get rid of backgorund, though.
% Or look for clusters/connected components of values in the mammogram (after background reduction) and crop those (boundig box) and train on them, this way i don't need to send the big mammogram but just these cropped parts (in case there is not enough memory). Note: for components to be separated they have to be at least 128 pixels apart (because i have to preserve surroundig region, too). This is not gonna work, because the connected component is going to be the entire breast area, see some examples if you doubt it.
% Or maybe just crop after background reduction to get rid of some parts that are not needed. Will I win a lot, though?. It looks like I won't. Don't do
% cutting mammograms in 4 or 16 pieces for training woul dnot be that bad, in fact as long as i overlap the regions a little bit and use no padding in the first layer (instead of padding it should have the original surrounding region, this is what decides what overlpas i need when i divide in 4 or 16). The results are gonna be exactkly as if i trained with every single patch in the image or with the entire image. This if i have no memory, or maybe if i wan to change up a bit. I would have to cut the labellings too, but that's not much o f aprobem as long as the training is the same as if it were end-to-end, which it is.
	
	\subsection{Data augmentation}
	Rotations and flipping of original big images. the breast and cannals, and nipple may be very different at 90 and 270, flipping an 180 seem fine. Or maybe not.


	\subsection{Data division}
	70/15/15 is a good split. stratified per patient, this total number of patients in each set and this total number of mammograms (after augmentation) and this total number of lesions.
% do alittle table with rows being percentage of data set, patients, mammograms, # of masses and columns being training, validation test.That way I syummarize all information. i can also add a total column, summing over all trainng and test set.

\chapter{Solution Model}
\label{ch:Model}
We document here design decisions, its rationale and implemetation notes.

%We document here how we tranform/reduce the breast cancer detection and diagnosis task into a machine learning task able to be taken by convolutional networks, i.e., how we produce a data set with $m$ inputs $x^{(i)} \in \mathbb{R}^n$ and $m$ corresponding labels $y^{(i)}$. We use this notation throughout this section. 

\section{Task definition}
Segment lesions (tumors or all massses) (benign and malignant or only malignant) from normal tissue. Masses or microcalcifications.
%We use digital mammograms to detect breast masses and produce a valid image segmentation.


\section{Data set}

	\subsection{Database}
	\input{model/database}

	\subsection{BCDR-DM}
	Yet to write
% Files and how are they organized. Data available per case and per mammogram. How are boundaries written. formats, etc.
% 159 calcifications, 36 micro, 11 micro+calcif, thus 108 micro or calcif. 106 nodule, 20 nodule+ calcific, 11 nodule + micro
	
	\subsection{Image retrieval/Preprocessing}
	\input{model/imageRetrieval} 
% Images will not be zero-centered , normalized or whitened. global contrast

	\subsection{Data set}
	Yet to write
% We have x number of images with x positives and negatives. Resunmied in Table...
	
	\subsection{Data augmentation}
	Rotations and flipping of original big images


	\subsection{Data division}
	70/15/15 is a good split. stratified per patient, this total number of patients in each set and this total number of mammograms (after augmentation) and this total number of lesions.

\section{Model}
	\subsection{Architecture}
	Using the advice in Section~\ref{subsec:PracticalDL} we decided to use a simple network with six convolutional layers and two fully connected layers with the following architecture:
	\begin{table}[h]
		\centering
		\begin{tabular}{lccccr}
		\hline
		\textbf{Layer} & \textbf{Filter} & \textbf{Stride} &\textbf{Pad} & \textbf{Volume} & \textbf{Params} \\
		\hline
		\texttt{INPUT}	& -	& - & - & $127 \times 127 \times 1$ & -\\
		\texttt{CONV -> RELU} & $5 \times 5$ & 2 & 2 & $64 \times 64 \times 64$ & 1\,625\\
		\texttt{CONV -> RELU} & $3 \times 3$ & 1 & 1 & $64 \times 64 \times 64$ & 36\,928\\
		\texttt{MAXPOOL} & $2 \times 2$ & 2 & 0 & $32 \times 32 \times 64$ & -\\
		\texttt{CONV -> RELU} & $3 \times 3$ & 1 & 1 & $32 \times 32 \times 96$ & 55\,392\\
		\texttt{CONV -> RELU} & $3 \times 3$ & 1 & 1 & $32 \times 32 \times 96$ & 83\,040\\
		\texttt{MAXPOOL} & $2 \times 2$ & 2 & 0 & $16 \times 16 \times 96$ & -\\
		\texttt{CONV -> RELU} & $3 \times 3$ & 1 & 1 & $16 \times 16 \times 128$ & 110\,720\\
		\texttt{CONV -> RELU} & $3 \times 3$ & 1 & 1 & $16 \times 16 \times 128$ & 147\,584\\
		\texttt{MAXPOOL} & $2 \times 2$ & 2 & 0 & $8 \times 8 \times 128$ & -\\
		\texttt{FC -> RELU} & $8 \times 8$ & - & - & $1 \times 1 \times 512$ & 4\,194\,816\\
		\texttt{FC -> SIGMOID} & $1 \times 1$ & - & - & $1 \times 1 \times 1$ & 513 \\
		\hline
		\end{tabular}
		\label{tab:convNetArchitecture}
		\caption[Selected convolutional network architecture]{Architecture of the network used for experiments. It shows the filter, stride and padding used in each layer as well as the resulting volume and the number of learnable parameters per layer.}
	\end{table}

	The first convolutional layer uses a $5 \times 5$ filter with stride 2 (padding 2) to reduce the input spatial size from $127 \times 127$ to $64 \times 64$. After that all filters are $3 \times 3$ with stride 1 (padding 1), which preserves the spatial size and the pooling is $2\times 2$ stride 2 (padding 0) which reduces the spatial size by a half. This architecture has 4.63 million learnable parameters. 

	In case the input was size $64 \times 64$ pixels we could replace use a $3 \times 3$ filter with stride 1 in the first convolutional layer and leave everything else unchanged. For an all convolutional architecture we could replace all pooling layers by a $5 \times 5$ filter  with stride 2 and use input images of size of $113 \times 113$ or $129 \times 129$.

	% Replacing the pooling layers by convolutional layers or overlapping pooling could marginally improve results. doing it all convolutional  is not that expensive and produces better results.
% Masses are 12.2mm + 4.5mm std . 2 cm holds 96% of masses. 1.5 holds 73 % of masses

\section{Training}
%Details about the practical decsiions taken to archotectures, and hyperparamters per experiments.

	\subsection{Hardware}
	Training deep neural networks is computationally intensive and requires equipment with powerful GPUs. We enlist here the resources available for this thesis.
	\begin{table}[h]
		\centering
		\begin{tabular}{cp{3.9cm}p{1.7cm}p{1.8cm}cc}
		\hline
		\textbf{PC}	& \textbf{GPU}	& \textbf{HD}	& \textbf{CPU}	& \textbf{RAM}	& \textbf{\#} \\
		\hline
		Personal	& Nvidia NVS 5400M \newline 96 cores, 1GB, 2.1 compatibility, 29 GB/s	& 57 GB \newline (36 free)	& i5-3210M \newline 2.5GHz	& 4 GB	& 1 \\
		A4-401	& Nvidia Quadro K620 \newline 384 cores, 2GB, 5.0 compatibility, 29 GB/s & 240 GB \newline (230 free)	& i5-4570 \newline 3.2GHz	& 8 GB	& 27\\

		\hline
		\end{tabular}
		\caption{Available hardware for experiments}
	\end{table}
	% We did our experiments in x computers from A3-401

	\subsection{Software}
	We use Caffe~\cite{Jia2014} to train the networks and Python to develop any other tools (image retrieval and augmentation, model evaluation, figure generation, etc.).

	\subsection{Implementation details}
	Python, libraries used,etc.

	\section{Regularization}
Dropout and l2-norm
Other options: batch normalization

\section{Evaluation}

\subsection{Post-processing}
Probabilities vs UNcorrected threshold vs Threshold and cluster extent correction vs threshold-free cluster enhancement vs, show different results at different thresholds
data is smooth, 

uncorrected threshold
Present the probabilities of tumor on each pixel. anmd threshold it on a given prob nd delete any clusters less than x.
Threshold free cluster enhancement (see module 29 in introduction to fmri)
Choose a threshold and delete any clusters less than x...

we could also present a heatmap with the different probabilities in each pixel of the image, for instance on mammograms we could present a grayscale image of whether a lesion is present.

%Upsampling can be done using ndimage.zoom or scipy.misc.imresize or Image.resize (http://stackoverflow.com/questions/13242382/resampling-a-numpy-array-representing-an-image) and the cubic interpolation is almost certainly differentiable.
% write a zero-padding function, i will need it if i do manual upsampling(instead of a python function) or if the network learn it  and when calculating gradients in any case
% For interpolations, see http://paulbourke.net/miscellaneous/interpolation/ y las definiciones de bilinear y bicubic above
% for training the option is to downsample the ground truth, to add a bilinear layer as part of the network or to add a learnable layer as part of the network

% CRFs: public available implementation of (Krahenbuhl & Koltun)
% For the figure draw a random one  of 100x100 with a little signal in there and apply all corrections.

% If using the threshold/ value under the cluster one, use the validation set t select pairs(threshold, total acceptable value)

% Background is thresholded at zero and shown in black

	\subsection{Evaluation}
	When dividing the data set we make sure \textit{all} image patches obtained from the same patient are assigned to either the training set or test set (not distributed) to avoid any possible overfit to the test set. Given that our data is unbalanced, with far more negative than positive examples, we use PRAUC (see Section~\ref{subsec:Classification}) to choose between models for hyperparameter selection and as an overall performance metric. Other metrics are also reported for completeness. 

	We could also evaluate the network on all augmentations of an image and output the average prediction; in theory, this would give us better results. For simplicity, we do not apply it for model selection.

	For detection of lesions on entire mammograms we slide the trained convolutional network across the mammogram computing a per-pixel prediction. The generated heatmap preserves the size of the original mammogram (with some zero-padding) and can be presented side to side to the original mammogram as a CAD system. In case this heatmap is noisy (predictions changes abruptly from pixel to pixel) we could use a median or gaussian filter to smooth it out.% We do not evaluate the network on the entire mammogram (or per patient), we limit ourselves to show the results.
	\subsection{Evaluation metrics}

We describe how we evaluate our results.

\subsection{Post-processing}
We aim to evaluate convolutional networks as a single end-to-end segmentation model;
%component in an end-to-end segmentation task;
thus, we choose to use the produced heatmaps without any post-processing. However, adding post-processing to our best performing architecture will certainly improve results and remains as a promising future endeavor.% In any case, having a strong network to start with is needed to produce good results.

% Options:
% uncorrected threshold: Select a threshold, take that as segementation
% Cluster-extent correction: Delete thresholds that are under a number of pixels 
% or whose total probability is less than a desired number. Needs this number
% Threshold-free cluster enhancement (module 29 in introduction to fmri): Same as aove but withouth a cluster (?)
% Number of clusters per image: do threshold-free enhancement where the metric is to 
% leave only the most promising cluster
% Conditional random fields (CRF): Work quite well. Python implementation of CRF: https://pystruct.github.io/auto_examples/image_segmentation.html Here is another take: http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html Any look fine.

\subsection{Segmentation}
We generate a segmentation by setting each pixel whose value was zero in the original mammogram to background (0), each non-background pixel whose logit is greater than a threshold to breast mass (255) and any remaining pixel to normal breast tissue (127).

Using the validation set, we compute the IOU for different thresholds and select the one that produces the best result. This threshold is used to produce the final segmentation.

% Using the validation set, we compute the IOU for different thresholds and select the one that produces the best result. The final segmentation is generated by setting each pixel whose value was zero in the original mammogram to background (0), each non-background pixel whose logit is greater than the threshold to breast mass (255) and any remaining pixel to normal breast tissue (127).

\subsection{Metrics}
We present results for IOU, F1-score, G-mean, accuracy, sensitivity, specificity, precision and recall.
All metrics are calculated only on the breast area, i.e., the task is reduced to binary segmentation with breast mass as the positive class and breast tissue as the negative class; background is easily segmented by thresholding to zero so we ignore it.
We use IOU as our preferred performance metric.

%We could also evaluate the network on all augmentations of an image and output the average prediction; in theory, this would give us better results. For simplicity, we do not apply it for model selection.

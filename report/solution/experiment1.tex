We use a simple architecture to have a baseline performance for convolutional networks and test the effect of using a weighted loss function and enhancing the input images.

\subsection{Architecture}
\begin{table}[h!]
	\centering
	\begin{tabular}{lcccccr}
	\hline
	\textbf{Layer} & \textbf{Filter} & \textbf{Stride} & \textbf{Pad} & \textbf{Dilation} & \textbf{Volume} & \textbf{Parameters} \\
	\hline
	\texttt{INPUT}	&- & -	& - & - & $52 \times 52 \times 1$ & -\\
	\texttt{CONV -> RELU}	& $5 \times 5$ & 2 & 2 & 1 & $26 \times 26 \times 32$ & 832\\
	\texttt{CONV -> RELU}	& $3 \times 3$ & 1 & 1 & 1 & $26 \times 26 \times 32$ & 9\,248\\
	\texttt{CONV -> RELU}	& $3 \times 3$ & 2 & 1 & 1 & $13 \times 13 \times 64$ & 18\,496\\
	\texttt{CONV -> RELU}	& $3 \times 3$ & 1 & 1 & 1 & $13 \times 13 \times 64$ & 36\,928\\
	\texttt{CONV -> RELU}	& $3 \times 3$ & 1 & 2 & 2 & $13 \times 13 \times 96$ & 55\,392\\
	\texttt{CONV -> RELU}	& $3 \times 3$ & 1 & 2 & 2 & $13 \times 13 \times 96$ & 83\,040\\
	\texttt{CONV}			& $5 \times 5$ & 1 & 6 & 3 & $13 \times 13 \times 1$ & 2\,401\\
	\texttt{BILINEAR (x4)}	& - & - && - & $52 \times 52 \times 1$ & -\\
	\hline
	\end{tabular}
	\caption[Convolutional network architecture for Experiment 1]{Architecture of the network used for the first experiments. It shows the filter size, stride, padding and dilation in each layer as well as the resulting volume and number of learnable parameters per layer.}
	\label{tab:convNetArchitecture1}
\end{table} % 206 337 params

Each image is whitened (zero-mean centered and divided by its standard deviation) individually before being input. 
The first convolutional layer reduces the spatial dimensions of the input from $52 \times 52$ to $26 \times 26$ to reduce the number of parameters and memory requirements while augmenting its receptive field. Subsequent convolutional layers preserve the dimensions of its input volume relegating subsampling to pooling layers. 
Finally, the volume is upsampled by a factor of 4 to recover the dimensions of the original image (Sec.~\ref{sec:Segmentation}). The network outputs a heatmap of logits with the same size as the input image.
%We produce a heatmap of logits rather than probabilities to improve numerical stability.

The effective receptive field of the network is $101 \times 101$ pixels that equates to $2.1 \times 2.1$ cms. This architecture uses 206\,337 parameters. %2 906 681

\subsection{Regularization}
We use l2-norm regularization with $\lambda$ selected using a validation set as explained in Sec.~\ref{subsec:Hyperparameters}.

\subsection{Loss function}
We compute the logistic loss function for each pixel in the produced segmentation and average the loss over pixels in the breast area---background is ignored. This amounts to using a weighted loss function where errors in the breast tissue and masses are weighted by one and those in the background are weighted by zero.

\subsection{Experiments}
We performed three experiments using this architecture:
\subsubsection{Experiment 1.1} 
To obtain a performance baseline, we trained this simple network in minimally processed images, i.e., mammograms without any enhancement.

\subsubsection{Experiment 1.2} 
\label{subsec:Experiment1_2}
To fight the class imbalance produced by breast mass pixels being rare in comparison to normal breast tissue pixels, we modify the loss function by weighting the losses over masses by 15, those over normal breast tissue by 1 and ignoring those over the background. Assigning a higher value to errors on breast masses forces the network to invest more resources in correctly classifying masses, thus learning better features to avoid this costly errors~\cite{Provost2000}. As in Experiment 1.1, we use input without enhancement
%This technique balances the total sum of losses from the common class (normal breast tissue) with that of the rare class (breast masses) and is often used to fight class imbalance.

\subsubsection{Experiment 1.3}
In the final experiment, we combine both a weighted loss function and enhanced input images.

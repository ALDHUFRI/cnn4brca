Here I document each decision taken and its possible alternatives. The first one is the one I took, the others are ordered according to what I believe would be the next best.

-- Data set
Lesions
	Masses
	Calcifications and microcalcifications
Mammograms
	Digital from BCDR
	Film from DDSM
Division
	70% training, 15% val, 15% test
	70% training, 10% val, 20% test
Enhancement
	Global background reduction + contrast stretching
	Global contrast stretching/No enhancement	
	Local contrast stretching
	local background reduction + contrast
Image size
	Reduced for 2cm to fit into 112 x 112 pixels (or as many pixels as the input
		volume to the network). Train on entire images
	Cut 112 x 112 patches (or as many pixels as the input volume) equivalent to
		2cm x 2cm. Roughly 1M patches. This will take advantage of smaller
		mini-batches/ more frequent updates, batchnorm, dropout (this may 
		work in both) and less memory use (bigger input volume and newer
		architectures could be used). Train on patches. 
Downsampling interpolation (images and labels)
	LANCZOS filter from PILLOW
	BICUBIC filter form PILLOW
Cropping
	Cropping to breast area to not have lots of black space (smaller images)
	No cropping
Augmentation
	Flipped and rotations 0,90,180,270 (8). Test set not augmented
	Flipped and rotations 0,180 (4). Test set not augmented
Storage
	Store all augmented images and its augmented labels
	Store originals and sample an image and a data augmentation for every
		training batch
Label storage
	Store one version at same size than downsampled image (~1100x1100) and one
		version that matches dimension of output of the network (~70x70)
	Only keep the big version (further downsampling can be done during training)
Folders
	Mammograms and their augmentations in the same folders and create list with
		all their names (180x8 names). Labels names are generated with suffix

--Model
ConvNet architecture
	The one starting at 112 (2.8M parameters) (arch #11)
	The one starting at 80 (2.8M parameters) (arch #18)
	The one starting at 96 (1.6M parameters) (arch #12)
	The one with new features (2.6M parameters) (arch #17)
Modern features/trends not adopted
	7x7 average pooling filters instead of fully connected
	4x4 conv filters, stride 2, padding 1, to get rid of pooling
	deeper architecture
	more feature maps 
	no dropout (just batchnorm)
Upsampling
	Downsample the labels (PILLOW Image.NEAREST)
	Upsample the produced output with bicubic interpolation at end of network
	Upsample the produced output with deconvolutional layer at end of network
	Upsample the produced output with bilinear interpolation at end of network.
Loss function
	Logistic loss averaged over breast area only
	Logistic loss summed over breast area only
	Hinge/SVM loss averaged over breast area only

--Training
Local zero-mean center each image
	Before training (subtract the mean intensity across the preprocessed image)
	Leave as is
Activation function
	LeakyRelu
	ReLu
Update Rule
	Adam
	NAG
Pooling
	Non-overlapping max-pooling
	Convolutional overlapping pooling (4x4 pooling, stride 2, padding 1)
	Overlapping max-pooling
First layer Conv-Pooling
	6x6 filter stride 2 padding 2
	4x4 filter stride 2 padding 1
Batch size
	One entire image per batch
	As many as memory supports
Regularization
	Dropout + BatchNorm + Regularization
Software
	Tensorflow
	Keras
Learning rate
	Biggest not causing divergence and halve when converged

---Post-processing
Post-processing
	?
Evaluation metric
	IOU
	F1-score

TO DO:
% Train a simple convolutional (validate lambda)
% Train one with bells and whistles(choosen by heart) (threshold moving)  (validate lambda and alpha)
% Test different configurations (normalizations, bigger smaller input, etc)
% Choose better hyperparameters (threshold moving)
% Unbalanced datasets (data replication, threshold moving)
% For final model, use both(only convolutions and conv&pool)
% Use VGG Net pretrained in Caffe.
% Use vairous image features as a feature map of the input volume 
% Train an ensemble of networks with different hyperparameters at the start and average.

More Ideas:
% What about visualizaing the output (http://googleresearch.blogspot.mx/2015/06/inceptionism-going-deeper-into-neural.html). What a mass looks like?, what a microcalcific looks like?
% Maybe use inceptionism to create some new data. (dtaa augmentation)
% What aobut including other parameters as a feature (age, date, whatever). So use the convnet as a feature extractor and then add those data and done
